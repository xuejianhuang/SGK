2024-10-30 03:49:54,631 - ============================== args ==============================
2024-10-30 03:49:54,631 - dataset: twitter
2024-10-30 03:49:54,631 - model: SGKE
2024-10-30 03:49:54,631 - batch: 32
2024-10-30 03:49:54,631 - seed: 666
2024-10-30 03:49:54,631 - ============================== End args ==============================
2024-10-30 03:49:54,631 - ============================== config ==============================
2024-10-30 03:49:54,631 - BertModel: <class 'transformers.models.bert.modeling_bert.BertModel'>
2024-10-30 03:49:54,631 - BertTokenizer: <class 'transformers.models.bert.tokenization_bert.BertTokenizer'>
2024-10-30 03:49:54,631 - att_dropout: 0
2024-10-30 03:49:54,632 - att_num_heads: 8
2024-10-30 03:49:54,632 - batch_size: 32
2024-10-30 03:49:54,632 - bert_dir: ./bert-base-multilingual-uncased/
2024-10-30 03:49:54,632 - bert_freeze: False
2024-10-30 03:49:54,632 - classifier_hidden_dim: 128
2024-10-30 03:49:54,632 - decayRate: 0.96
2024-10-30 03:49:54,632 - device: cuda
2024-10-30 03:49:54,632 - edge_feats: 768
2024-10-30 03:49:54,632 - epoch: 10
2024-10-30 03:49:54,632 - f_dropout: 0
2024-10-30 03:49:54,632 - hidden_dim: 768
2024-10-30 03:49:54,632 - img_dim: 768
2024-10-30 03:49:54,632 - knowledge_enhanced: True
2024-10-30 03:49:54,632 - lr: 5e-05
2024-10-30 03:49:54,632 - max_captions_num: 5
2024-10-30 03:49:54,632 - max_images_num: 5
2024-10-30 03:49:54,632 - model_saved_path: ./best_model/
2024-10-30 03:49:54,632 - n_layers: 2
2024-10-30 03:49:54,632 - node_feats: 768
2024-10-30 03:49:54,632 - num_classes: 3
2024-10-30 03:49:54,632 - num_heads: 2
2024-10-30 03:49:54,632 - out_feats: 768
2024-10-30 03:49:54,632 - patience: 3
2024-10-30 03:49:54,632 - resnet101_path: ./ResNet/resnet101-5d3b4d8f.pth
2024-10-30 03:49:54,632 - resnet50_path: ./ResNet/resnet50-11ad3fa6.pth
2024-10-30 03:49:54,632 - swin_transformer: ./swin-transformer
2024-10-30 03:49:54,632 - test_ratio: 0.1
2024-10-30 03:49:54,632 - text_dim: 768
2024-10-30 03:49:54,632 - text_max_length: 40
2024-10-30 03:49:54,632 - torch: <module 'torch' from '/home/huang001/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>
2024-10-30 03:49:54,632 - train_ratio: 0.8
2024-10-30 03:49:54,632 - twitter_dataset_dir: ./data/Twitter/
2024-10-30 03:49:54,632 - val_ratio: 0.1
2024-10-30 03:49:54,632 - weibo_dataset_dir: ./data/Weibo/
2024-10-30 03:49:54,632 - ============================== End config ==============================
2024-10-30 03:50:00,402 - total number of parameters:240711671
2024-10-30 03:50:00,408 - -----------Epoch:0-----------
2024-10-30 04:11:58,574 - train_loss:0.40194 train_acc:0.801
2024-10-30 04:14:13,290 - val_loss:0.20219 val_acc:0.919 

2024-10-30 04:14:14,622 - save model,acc:0.919
2024-10-30 04:14:14,622 - -----------Epoch:1-----------
2024-10-30 04:36:09,190 - train_loss:0.14701 train_acc:0.937
2024-10-30 04:38:22,542 - val_loss:0.09394 val_acc:0.958 

2024-10-30 04:38:24,317 - save model,acc:0.958
2024-10-30 04:38:24,317 - -----------Epoch:2-----------
2024-10-30 05:00:10,126 - train_loss:0.06224 train_acc:0.975
2024-10-30 05:02:23,320 - val_loss:0.15139 val_acc:0.942 

2024-10-30 05:02:23,321 - -----------Epoch:3-----------
2024-10-30 05:24:05,904 - train_loss:0.04028 train_acc:0.983
2024-10-30 05:26:18,583 - val_loss:0.10780 val_acc:0.951 

2024-10-30 05:26:18,584 - -----------Epoch:4-----------
2024-10-30 05:47:57,708 - train_loss:0.01056 train_acc:0.996
2024-10-30 05:50:10,343 - val_loss:0.11042 val_acc:0.946 

2024-10-30 05:52:25,036 - --------------------- test results-------------------------------
2024-10-30 05:52:25,037 - acc:0.9460571  prec:[0.9611111 0.9579832 0.9551282]  rec:[0.97740114 0.88372093 0.9770492 ]  f1:[0.9691877  0.91935486 0.9659643 ]
2024-10-30 05:52:25,037 - confusion: 
[[173   3   1]
 [  2 114  13]
 [  5   2 298]]
2024-10-30 05:52:25,099 - the running time is: 7344.7 s
