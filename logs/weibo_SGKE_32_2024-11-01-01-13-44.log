2024-11-01 01:13:44,227 - ============================== args ==============================
2024-11-01 01:13:44,227 - dataset: weibo
2024-11-01 01:13:44,227 - model: SGKE
2024-11-01 01:13:44,228 - batch: 32
2024-11-01 01:13:44,228 - seed: 666
2024-11-01 01:13:44,228 - ============================== End args ==============================
2024-11-01 01:13:44,228 - ============================== config ==============================
2024-11-01 01:13:44,228 - BertModel: <class 'transformers.models.bert.modeling_bert.BertModel'>
2024-11-01 01:13:44,228 - BertTokenizer: <class 'transformers.models.bert.tokenization_bert.BertTokenizer'>
2024-11-01 01:13:44,228 - att_dropout: 0
2024-11-01 01:13:44,228 - att_num_heads: 8
2024-11-01 01:13:44,228 - batch_size: 32
2024-11-01 01:13:44,228 - bert_dir: ./bert-base-multilingual-uncased/
2024-11-01 01:13:44,228 - bert_freeze: False
2024-11-01 01:13:44,228 - classifier_hidden_dim: 128
2024-11-01 01:13:44,228 - decayRate: 0.96
2024-11-01 01:13:44,228 - device: cuda
2024-11-01 01:13:44,228 - edge_feats: 768
2024-11-01 01:13:44,228 - epoch: 10
2024-11-01 01:13:44,228 - f_dropout: 0
2024-11-01 01:13:44,228 - hidden_dim: 768
2024-11-01 01:13:44,228 - img_dim: 768
2024-11-01 01:13:44,228 - knowledge_enhanced: True
2024-11-01 01:13:44,228 - lr: 5e-05
2024-11-01 01:13:44,228 - max_captions_num: 5
2024-11-01 01:13:44,228 - max_images_num: 5
2024-11-01 01:13:44,228 - model_saved_path: ./best_model/
2024-11-01 01:13:44,228 - n_layers: 2
2024-11-01 01:13:44,228 - node_feats: 768
2024-11-01 01:13:44,228 - num_classes: 3
2024-11-01 01:13:44,228 - num_heads: 2
2024-11-01 01:13:44,228 - out_feats: 768
2024-11-01 01:13:44,228 - patience: 3
2024-11-01 01:13:44,228 - resnet101_path: ./ResNet/resnet101-5d3b4d8f.pth
2024-11-01 01:13:44,228 - resnet50_path: ./ResNet/resnet50-11ad3fa6.pth
2024-11-01 01:13:44,228 - swin_transformer: ./swin-transformer
2024-11-01 01:13:44,229 - test_ratio: 0.1
2024-11-01 01:13:44,229 - text_dim: 768
2024-11-01 01:13:44,229 - text_max_length: 40
2024-11-01 01:13:44,229 - torch: <module 'torch' from '/home/huang001/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>
2024-11-01 01:13:44,229 - train_ratio: 0.8
2024-11-01 01:13:44,229 - twitter_dataset_dir: ./data/Twitter/
2024-11-01 01:13:44,229 - val_ratio: 0.1
2024-11-01 01:13:44,229 - weibo_dataset_dir: ./data/Weibo/
2024-11-01 01:13:44,229 - ============================== End config ==============================
2024-11-01 01:13:51,575 - total number of parameters:240711671
2024-11-01 01:13:51,580 - -----------Epoch:0-----------
2024-11-01 01:40:21,024 - train_loss:0.43853 train_acc:0.807
2024-11-01 01:42:56,952 - val_loss:0.29183 val_acc:0.876 

2024-11-01 01:42:58,482 - save model,acc:0.876
2024-11-01 01:42:58,483 - -----------Epoch:1-----------
2024-11-01 02:09:04,002 - train_loss:0.22489 train_acc:0.907
2024-11-01 02:11:37,204 - val_loss:0.25979 val_acc:0.864 

2024-11-01 02:11:37,204 - -----------Epoch:2-----------
2024-11-01 02:37:23,379 - train_loss:0.11869 train_acc:0.957
2024-11-01 02:39:55,296 - val_loss:0.23110 val_acc:0.908 

2024-11-01 02:39:57,047 - save model,acc:0.908
2024-11-01 02:39:57,047 - -----------Epoch:3-----------
2024-11-01 03:05:29,244 - train_loss:0.05084 train_acc:0.984
2024-11-01 03:08:02,281 - val_loss:0.23561 val_acc:0.913 

2024-11-01 03:08:04,028 - save model,acc:0.913
2024-11-01 03:08:04,028 - -----------Epoch:4-----------
2024-11-01 03:33:15,868 - train_loss:0.03601 train_acc:0.987
2024-11-01 03:35:47,916 - val_loss:0.24194 val_acc:0.913 

2024-11-01 03:35:47,917 - -----------Epoch:5-----------
2024-11-01 04:01:26,944 - train_loss:0.01215 train_acc:0.996
2024-11-01 04:04:01,087 - val_loss:0.26356 val_acc:0.910 

2024-11-01 04:04:01,087 - -----------Epoch:6-----------
2024-11-01 04:29:35,601 - train_loss:0.02096 train_acc:0.993
2024-11-01 04:32:07,735 - val_loss:0.25162 val_acc:0.908 

2024-11-01 04:34:49,268 - --------------------- test results-------------------------------
2024-11-01 04:34:49,269 - acc:0.9197413  prec:[0.9591837 0.9230769 0.9216216]  rec:[0.9710744  0.82758623 0.96056336]  f1:[0.9650924 0.8727273 0.9406897]
2024-11-01 04:34:49,269 - confusion: 
[[235   2   5]
 [  6 144  24]
 [  4  10 341]]
2024-11-01 04:34:49,333 - the running time is: 12057.8 s
