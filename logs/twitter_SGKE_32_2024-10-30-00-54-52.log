2024-10-30 00:54:52,055 - ============================== args ==============================
2024-10-30 00:54:52,055 - dataset: twitter
2024-10-30 00:54:52,055 - model: SGKE
2024-10-30 00:54:52,055 - batch: 32
2024-10-30 00:54:52,055 - seed: 666
2024-10-30 00:54:52,055 - ============================== End args ==============================
2024-10-30 00:54:52,055 - ============================== config ==============================
2024-10-30 00:54:52,055 - BertModel: <class 'transformers.models.bert.modeling_bert.BertModel'>
2024-10-30 00:54:52,055 - BertTokenizer: <class 'transformers.models.bert.tokenization_bert.BertTokenizer'>
2024-10-30 00:54:52,055 - att_dropout: 0
2024-10-30 00:54:52,055 - att_num_heads: 8
2024-10-30 00:54:52,055 - batch_size: 32
2024-10-30 00:54:52,055 - bert_dir: ./bert-base-multilingual-uncased/
2024-10-30 00:54:52,055 - bert_freeze: False
2024-10-30 00:54:52,055 - classifier_hidden_dim: 128
2024-10-30 00:54:52,055 - decayRate: 0.96
2024-10-30 00:54:52,056 - device: cuda
2024-10-30 00:54:52,056 - edge_feats: 768
2024-10-30 00:54:52,056 - epoch: 10
2024-10-30 00:54:52,056 - f_dropout: 0
2024-10-30 00:54:52,056 - hidden_dim: 768
2024-10-30 00:54:52,056 - img_dim: 768
2024-10-30 00:54:52,056 - knowledge_enhanced: True
2024-10-30 00:54:52,056 - lr: 5e-05
2024-10-30 00:54:52,056 - max_captions_num: 5
2024-10-30 00:54:52,056 - max_images_num: 5
2024-10-30 00:54:52,056 - model_saved_path: ./best_model/
2024-10-30 00:54:52,056 - n_layers: 2
2024-10-30 00:54:52,056 - node_feats: 768
2024-10-30 00:54:52,056 - num_classes: 3
2024-10-30 00:54:52,056 - num_heads: 2
2024-10-30 00:54:52,056 - out_feats: 768
2024-10-30 00:54:52,056 - patience: 3
2024-10-30 00:54:52,056 - resnet101_path: ./ResNet/resnet101-5d3b4d8f.pth
2024-10-30 00:54:52,056 - resnet50_path: ./ResNet/resnet50-11ad3fa6.pth
2024-10-30 00:54:52,056 - swin_transformer: ./swin-transformer
2024-10-30 00:54:52,056 - test_ratio: 0.1
2024-10-30 00:54:52,056 - text_dim: 768
2024-10-30 00:54:52,056 - text_max_length: 40
2024-10-30 00:54:52,056 - torch: <module 'torch' from '/home/huang001/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>
2024-10-30 00:54:52,056 - train_ratio: 0.8
2024-10-30 00:54:52,056 - twitter_dataset_dir: ./data/Twitter/
2024-10-30 00:54:52,056 - val_ratio: 0.1
2024-10-30 00:54:52,056 - weibo_dataset_dir: ./data/Weibo/
2024-10-30 00:54:52,056 - ============================== End config ==============================
2024-10-30 00:54:57,842 - total number of parameters:240711671
2024-10-30 00:54:57,847 - -----------Epoch:0-----------
2024-10-30 01:16:52,250 - train_loss:0.43088 train_acc:0.772
2024-10-30 01:19:10,942 - val_loss:0.18968 val_acc:0.901 

2024-10-30 01:19:12,133 - save model,acc:0.901
2024-10-30 01:19:12,133 - -----------Epoch:1-----------
2024-10-30 01:41:11,621 - train_loss:0.16805 train_acc:0.931
2024-10-30 01:43:30,620 - val_loss:0.14654 val_acc:0.931 

2024-10-30 01:43:32,398 - save model,acc:0.931
2024-10-30 01:43:32,398 - -----------Epoch:2-----------
2024-10-30 02:05:30,923 - train_loss:0.06511 train_acc:0.973
2024-10-30 02:07:49,857 - val_loss:0.15051 val_acc:0.938 

2024-10-30 02:07:51,631 - save model,acc:0.938
2024-10-30 02:07:51,631 - -----------Epoch:3-----------
2024-10-30 02:29:47,685 - train_loss:0.03234 train_acc:0.985
2024-10-30 02:32:06,640 - val_loss:0.14450 val_acc:0.950 

2024-10-30 02:32:08,504 - save model,acc:0.950
2024-10-30 02:32:08,504 - -----------Epoch:4-----------
2024-10-30 02:54:07,927 - train_loss:0.01496 train_acc:0.994
2024-10-30 02:56:27,133 - val_loss:0.14784 val_acc:0.938 

2024-10-30 02:56:27,134 - -----------Epoch:5-----------
2024-10-30 03:18:25,831 - train_loss:0.00829 train_acc:0.996
2024-10-30 03:20:44,649 - val_loss:0.17228 val_acc:0.939 

2024-10-30 03:20:44,649 - -----------Epoch:6-----------
2024-10-30 03:42:43,210 - train_loss:0.04749 train_acc:0.979
2024-10-30 03:45:01,519 - val_loss:0.21712 val_acc:0.935 

2024-10-30 03:47:21,915 - --------------------- test results-------------------------------
2024-10-30 03:47:21,916 - acc:0.9335599  prec:[0.96954316 0.89928055 0.94545454]  rec:[0.9502488 0.8802817 0.9701493]  f1:[0.959799   0.88967973 0.95764273]
2024-10-30 03:47:21,916 - confusion: 
[[191   7   3]
 [  5 125  12]
 [  1   7 260]]
2024-10-30 03:47:21,979 - the running time is: 10344.1 s
