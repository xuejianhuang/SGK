2024-11-01 06:47:49,709 - ============================== args ==============================
2024-11-01 06:47:49,709 - dataset: weibo
2024-11-01 06:47:49,709 - model: SGKE
2024-11-01 06:47:49,709 - batch: 32
2024-11-01 06:47:49,709 - seed: 666
2024-11-01 06:47:49,710 - ============================== End args ==============================
2024-11-01 06:47:49,710 - ============================== config ==============================
2024-11-01 06:47:49,710 - BertModel: <class 'transformers.models.bert.modeling_bert.BertModel'>
2024-11-01 06:47:49,710 - BertTokenizer: <class 'transformers.models.bert.tokenization_bert.BertTokenizer'>
2024-11-01 06:47:49,710 - att_dropout: 0
2024-11-01 06:47:49,710 - att_num_heads: 8
2024-11-01 06:47:49,710 - batch_size: 32
2024-11-01 06:47:49,710 - bert_dir: ./bert-base-multilingual-uncased/
2024-11-01 06:47:49,710 - bert_freeze: False
2024-11-01 06:47:49,710 - classifier_hidden_dim: 128
2024-11-01 06:47:49,710 - decayRate: 0.96
2024-11-01 06:47:49,710 - device: cuda
2024-11-01 06:47:49,710 - edge_feats: 768
2024-11-01 06:47:49,710 - epoch: 10
2024-11-01 06:47:49,710 - f_dropout: 0
2024-11-01 06:47:49,710 - hidden_dim: 768
2024-11-01 06:47:49,710 - img_dim: 768
2024-11-01 06:47:49,710 - knowledge_enhanced: True
2024-11-01 06:47:49,710 - lr: 5e-05
2024-11-01 06:47:49,710 - max_captions_num: 5
2024-11-01 06:47:49,710 - max_images_num: 5
2024-11-01 06:47:49,710 - model_saved_path: ./best_model/
2024-11-01 06:47:49,710 - n_layers: 2
2024-11-01 06:47:49,710 - node_feats: 768
2024-11-01 06:47:49,710 - num_classes: 3
2024-11-01 06:47:49,710 - num_heads: 2
2024-11-01 06:47:49,710 - out_feats: 768
2024-11-01 06:47:49,710 - patience: 3
2024-11-01 06:47:49,710 - resnet101_path: ./ResNet/resnet101-5d3b4d8f.pth
2024-11-01 06:47:49,710 - resnet50_path: ./ResNet/resnet50-11ad3fa6.pth
2024-11-01 06:47:49,710 - swin_transformer: ./swin-transformer
2024-11-01 06:47:49,710 - test_ratio: 0.1
2024-11-01 06:47:49,710 - text_dim: 768
2024-11-01 06:47:49,711 - text_max_length: 40
2024-11-01 06:47:49,711 - torch: <module 'torch' from '/home/huang001/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>
2024-11-01 06:47:49,711 - train_ratio: 0.8
2024-11-01 06:47:49,711 - twitter_dataset_dir: ./data/Twitter/
2024-11-01 06:47:49,711 - val_ratio: 0.1
2024-11-01 06:47:49,711 - weibo_dataset_dir: ./data/Weibo/
2024-11-01 06:47:49,711 - ============================== End config ==============================
2024-11-01 06:47:57,037 - total number of parameters:240711671
2024-11-01 06:47:57,041 - -----------Epoch:0-----------
2024-11-01 07:13:56,763 - train_loss:0.42976 train_acc:0.802
2024-11-01 07:16:33,028 - val_loss:0.23649 val_acc:0.914 

2024-11-01 07:16:34,803 - save model,acc:0.914
2024-11-01 07:16:34,869 - -----------Epoch:1-----------
2024-11-01 07:42:17,535 - train_loss:0.19175 train_acc:0.924
2024-11-01 07:44:53,374 - val_loss:0.20494 val_acc:0.913 

2024-11-01 07:44:53,374 - -----------Epoch:2-----------
2024-11-01 08:10:18,022 - train_loss:0.10731 train_acc:0.955
2024-11-01 08:12:53,406 - val_loss:0.21119 val_acc:0.925 

2024-11-01 08:12:55,226 - save model,acc:0.925
2024-11-01 08:12:55,226 - -----------Epoch:3-----------
2024-11-01 08:38:32,266 - train_loss:0.05860 train_acc:0.979
2024-11-01 08:41:07,504 - val_loss:0.27846 val_acc:0.905 

2024-11-01 08:41:07,504 - -----------Epoch:4-----------
2024-11-01 09:06:24,679 - train_loss:0.02659 train_acc:0.990
2024-11-01 09:08:59,252 - val_loss:0.25511 val_acc:0.923 

2024-11-01 09:08:59,252 - -----------Epoch:5-----------
2024-11-01 09:34:27,983 - train_loss:0.01660 train_acc:0.995
2024-11-01 09:37:03,375 - val_loss:0.30635 val_acc:0.904 

2024-11-01 09:39:43,583 - --------------------- test results-------------------------------
2024-11-01 09:39:43,583 - acc:0.92728287  prec:[0.92395437 0.83       0.97077924]  rec:[0.972     0.9431818 0.8666667]  f1:[0.94736844 0.88297874 0.91577333]
2024-11-01 09:39:43,584 - confusion: 
[[243   4   3]
 [  4 166   6]
 [ 16  30 299]]
2024-11-01 09:39:43,646 - the running time is: 10306.6 s
